{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loan Default Prediction Mock Project\n",
    "\n",
    "This notebook practices a complete Machine Learning pipeline, focusing on data preprocessing, feature engineering (one-hot encoding), class balancing (oversampling), model training (Random Forest), and rigorous evaluation (Classification Report).\n",
    "\n",
    "**Goal:** Predict loan default (`not.fully.paid` = 1) using the provided mock dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 0: Setup and Inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load Data\n",
    "Import necessary libraries and load the `mock_loan_data.csv` file into a DataFrame named `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import joblib\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('mock_loan_data.csv')\n",
    "\n",
    "# Check: Display the first 5 rows and data types\n",
    "print(\"--- First 5 Rows ---\")\n",
    "print(df.head())\n",
    "print(\"\\n--- DataFrame Info ---\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Irrelevant Column Removal\n",
    "Drop the `s.no` column as it is not a useful feature for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('s.no', axis=1)\n",
    "print(df.head(2)) # Check the column is removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task I: Feature Engineering (Categorical â†’ Numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. & 4. One-Hot Encode\n",
    "Apply One-Hot Encoding to the categorical columns: `purpose` and `grade`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns to encode\n",
    "categorical_cols = ['purpose', 'grade']\n",
    "\n",
    "# Apply One-Hot Encoding\n",
    "df = pd.get_dummies(df, columns=categorical_cols, dtype=int)\n",
    "\n",
    "# Check: Display the first 5 rows to confirm new columns (e.g., purpose_credit_card, grade_B)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task II: Data Preprocessing (Balancing Classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Check Imbalance\n",
    "Verify the class distribution of the target variable `not.fully.paid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Initial Class Distribution:\")\n",
    "print(df['not.fully.paid'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. & 7. Oversample Minority Class\n",
    "Split classes and use `resample` to oversample the minority class (1) to match the size of the majority class (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into majority and minority DataFrames\n",
    "df_majority = df[df['not.fully.paid'] == 0]\n",
    "df_minority = df[df['not.fully.paid'] == 1]\n",
    "\n",
    "# Oversample the minority class\n",
    "df_minority_upsampled = resample(\n",
    "    df_minority,\n",
    "    replace=True,  # Sample with replacement\n",
    "    n_samples=len(df_majority),  # To match majority class size\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Minority Upsampled Size:\", len(df_minority_upsampled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Combine and Shuffle\n",
    "Concatenate the DataFrames and shuffle the resulting balanced dataset to remove sequential bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine majority class with upsampled minority class\n",
    "df_balanced = pd.concat([df_majority, df_minority_upsampled], ignore_index=True)\n",
    "\n",
    "# Shuffle the entire dataset randomly\n",
    "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Check: Confirm balanced classes\n",
    "print(\"Balanced Class Distribution:\")\n",
    "print(df_balanced['not.fully.paid'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task IV: Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Separate X and y\n",
    "Define features ($\mathbf{X}$) and the target ($\mathbf{y}$), ensuring $\mathbf{y}$ is an integer type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = df_balanced.drop('not.fully.paid', axis=1)\n",
    "\n",
    "# Ensure target y is integer type\n",
    "y = df_balanced['not.fully.paid'].astype(int)\n",
    "\n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Shape of y:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Train/Test Split\n",
    "Split the data (80% train, 20% test). Use `stratify=y` to maintain the 50/50 class balance in both sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Training Samples:\", len(X_train))\n",
    "print(\"Testing Samples:\", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Initialize and Train Model\n",
    "Initialize the Random Forest Classifier and train it using the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Random Forest Model trained successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task V: Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Make Predictions\n",
    "Generate predictions on the unseen test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = rf.predict(X_test)\n",
    "\n",
    "print(\"Predictions generated on test set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Evaluate Performance\n",
    "Calculate and print Accuracy and the detailed Classification Report.\n",
    "\n",
    "*(Key focus: **Recall** for class 1 - how many actual defaults were correctly caught?)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Model Evaluation ---\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, pred):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task VI: Saving Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Serialize Model\n",
    "Save the trained model using `joblib` for future deployment or reuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serialize and save the model\n",
    "model_filename = 'loan_default_model.pkl'\n",
    "joblib.dump(rf, model_filename)\n",
    "\n",
    "print(f\"Trained model saved to {model_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
